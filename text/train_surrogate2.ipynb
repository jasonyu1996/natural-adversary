{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "from models import MLPClassifier, Baseline_Embeddings\n",
    "from models import Seq2Seq, MLP_D, MLP_G, MLP_I, MLP_I_AE, JSDistance, Seq2SeqCAE, Baseline_Embeddings, Baseline_LSTM\n",
    "from utils import to_gpu, Corpus, batchify, SNLIDataset, collate_snli\n",
    "import random\n",
    "import pickle as pkl\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original vocab 41574; pruned to 11004\n",
      "Number of sentences dropped from ./data/classifier/train.txt: 448221 out of 549367 total\n",
      "original vocab 41574; pruned to 11004\n",
      "Number of sentences dropped from ./data/classifier/test.txt: 8288 out of 9824 total\n"
     ]
    }
   ],
   "source": [
    "#python3.6 train_surrogate.py --data_path ./data/classifier --save_path game_output/ --classifier_path ./data --load_pretrained .\n",
    "cur_dir = '.'\n",
    "\n",
    "with open(cur_dir + '/vocab.json', 'r') as fin:\n",
    "    corpus_vocab = json.load(fin)\n",
    "\n",
    "corpus_train = SNLIDataset(train=True, vocab_size=11004-4, path='./data/classifier')\n",
    "corpus_test = SNLIDataset(train=False, vocab_size=11004-4, path='./data/classifier')\n",
    "trainloader= torch.utils.data.DataLoader(corpus_train, batch_size = 32, collate_fn=collate_snli, shuffle=True)\n",
    "train_iter = iter(trainloader)\n",
    "testloader= torch.utils.data.DataLoader(corpus_test, batch_size = 32, collate_fn=collate_snli, shuffle=False)\n",
    "random.seed(1111)\n",
    "np.random.seed(1111)\n",
    "torch.manual_seed(1111)\n",
    "\n",
    "EPS = 3e-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/game/.local/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'models.Seq2SeqCAE' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline_Embeddings(\n",
      "  (embedding_prem): Embedding(11004, 100)\n",
      "  (embedding_hypo): Embedding(11004, 100)\n",
      "  (linear): Linear(in_features=200, out_features=3, bias=True)\n",
      ")\n",
      "Seq2SeqCAE(\n",
      "  (embedding): Embedding(11004, 300)\n",
      "  (embedding_decoder): Embedding(11004, 300)\n",
      "  (encoder): Sequential(\n",
      "    (layer-1): Conv1d(300, 500, kernel_size=(3,), stride=(1,))\n",
      "    (bn-1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation-1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (layer-2): Conv1d(500, 700, kernel_size=(3,), stride=(2,))\n",
      "    (bn-2): BatchNorm1d(700, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation-2): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (layer-3): Conv1d(700, 1000, kernel_size=(3,), stride=(2,))\n",
      "    (bn-3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation-3): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (linear): Linear(in_features=1000, out_features=300, bias=True)\n",
      "  (decoder): LSTM(600, 300, batch_first=True)\n",
      "  (linear_dec): Linear(in_features=300, out_features=11004, bias=True)\n",
      ")\n",
      "MLP_I(\n",
      "  (layer1): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (bn1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation1): ReLU()\n",
      "  (layer2): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation2): ReLU()\n",
      "  (layer7): Linear(in_features=300, out_features=100, bias=True)\n",
      ")\n",
      "MLPClassifier(\n",
      "  (layers): Sequential(\n",
      "    (layer0): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (bn0): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation0): ReLU()\n",
      "    (layer1): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (bn1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation1): ReLU()\n",
      "  )\n",
      "  (linear): Linear(in_features=50, out_features=3, bias=True)\n",
      "  (log_softmax): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "autoencoder = torch.load(open(cur_dir + '/models/autoencoder_model.pt', 'rb'))\n",
    "#gan_gen = torch.load(open(cur_dir + '/models/gan_gen_model.pt', 'rb'))\n",
    "#gan_disc = torch.load(open(cur_dir + '/models/gan_disc_model.pt', 'rb'))\n",
    "inverter = torch.load(open(cur_dir + '/models/inverter_model.pt', 'rb'))\n",
    "\n",
    "classifier1 = Baseline_Embeddings(100, vocab_size=11004)\n",
    "# classifier1 = Baseline_LSTM(100,300,maxlen=10, gpu=args.cuda)\n",
    "\n",
    "classifier1.load_state_dict(torch.load('./models' + \"/baseline/model_emb.pt\"))\n",
    "vocab_classifier1 = pkl.load(open('./models' + \"/vocab.pkl\", 'rb'))\n",
    "\n",
    "mlp_classifier = MLPClassifier(100 * 2, 3, layers='100-50')\n",
    "#if not args.train_mode:\n",
    "mlp_classifier.load_state_dict(torch.load('./surrogate{0}.pt'.format('100-50')))\n",
    "\n",
    "print(classifier1)\n",
    "print(autoencoder)\n",
    "print(inverter)\n",
    "print(mlp_classifier)\n",
    "\n",
    "optimizer = optim.Adam(mlp_classifier.parameters(),\n",
    "                           lr=1e03,\n",
    "                           betas=(0.9, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def evaluate_model():\n",
    "    classifier1.eval()\n",
    "\n",
    "    test_iter = iter(trainloader)\n",
    "    correct=0\n",
    "    total=0\n",
    "    for batch in test_iter:\n",
    "        premise, hypothesis, target, _, _, _, _ = batch\n",
    "\n",
    "        if args.cuda:\n",
    "            premise=premise.cuda()\n",
    "            hypothesis = hypothesis.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        prob_distrib = classifier1.forward((premise, hypothesis))\n",
    "        predictions = np.argmax(prob_distrib.data.cpu().numpy(), 1)\n",
    "        correct+=len(np.where(target.data.cpu().numpy()==predictions)[0])\n",
    "        total+=premise.size(0)\n",
    "    acc=correct/float(total)\n",
    "    print(\"Accuracy:{0}\".format(acc))\n",
    "    return acc\n",
    "\n",
    "autoencoder.gpu = True\n",
    "autoencoder = autoencoder.cuda()\n",
    "autoencoder.start_symbols = autoencoder.start_symbols.cuda()\n",
    "#gan_gen = gan_gen.cuda()\n",
    "#gan_disc = gan_disc.cuda()\n",
    "classifier1 = classifier1.cuda()\n",
    "inverter = inverter.cuda()\n",
    "mlp_classifier = mlp_classifier.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_process(premise, hypothesis, target, premise_words, hypothesis_words, premise_length, hypothesis_length):\n",
    "    #mx = target.max().item()\n",
    "    #assert(mx >= 0 and mx < 3)\n",
    "    #for s, s_w in zip(premise, premise_words):\n",
    "    #    for i, w in zip(s, s_w):\n",
    "    #        assert(corpus_vocab.get(w, 3) == i)\n",
    "    #print(hypothesis_words, flush=True)\n",
    "    autoencoder.eval()\n",
    "    inverter.eval()\n",
    "    classifier1.eval()\n",
    "    mlp_classifier.train()\n",
    "\n",
    "    #print(premise.max().item(), flush=True)\n",
    "    #print(hypothesis.max().item(), flush=True)\n",
    "\n",
    "    premise_idx = torch.tensor([[corpus_vocab.get(w, 3) for w in s] for s in premise_words]).cuda()\n",
    "    hypothesis_idx = torch.tensor([[corpus_vocab.get(w, 3) for w in s] for s in hypothesis_words]).cuda()\n",
    "\n",
    "    c_prem = autoencoder.encode(premise_idx, premise_length, noise=False)\n",
    "    z_prem = inverter(c_prem).detach()\n",
    "\n",
    "    c_hypo = autoencoder.encode(hypothesis_idx, hypothesis_length, noise=False)\n",
    "    z_hypo = inverter(c_hypo).detach()\n",
    "\n",
    "    # z_comb = nn.cat((z_prem, z_hypo), 0).detach()\n",
    "\n",
    "    output = mlp_classifier(z_prem, z_hypo)\n",
    "    gold = classifier1((premise, hypothesis)).detach()\n",
    "\n",
    "    #print(output.shape, flush=True)\n",
    "    #print(gold.shape, flush=True)\n",
    "\n",
    "    acc = (torch.argmax(gold, 1) == target).to(torch.float32).mean().item()\n",
    "    acc_surrogate = (torch.argmax(output, 1) == target).to(torch.float32).mean().item()\n",
    "\n",
    "\n",
    "    loss = -torch.mean(torch.sum(output * F.softmax(gold, dim=1), 1), 0)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item(), acc, acc_surrogate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_pred(pw, hw):\n",
    "    classifier1.eval()\n",
    "\n",
    "    premise_idx = torch.tensor([vocab_classifier1.get(w, 3) for w in pw]).cuda().unsqueeze(0)\n",
    "    hypothesis_idx = torch.tensor([vocab_classifier1.get(w, 3) for w in hw]).cuda().unsqueeze(0)\n",
    "\n",
    "    return F.softmax(classifier1((premise_idx, hypothesis_idx)), 1).squeeze(0).cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(p, q):\n",
    "    q = torch.log(q)\n",
    "    a = p * q\n",
    "    a = torch.sum(a)\n",
    "    a = -a\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb(criterion, premise, hypothesis, target, premise_words, hypothesis_words, premise_length, hypothesis_length):\n",
    "    autoencoder.eval()\n",
    "    inverter.eval()\n",
    "    classifier1.eval()\n",
    "    mlp_classifier.eval()\n",
    "\n",
    "    premise_words = [premise_words]\n",
    "    hypothesis_words = [hypothesis_words]\n",
    "    premisea_length = [premise_length]\n",
    "    hypothesis_length = [hypothesis_length]\n",
    "\n",
    "\n",
    "    premise_idx = torch.tensor([[corpus_vocab.get(w, 3) for w in s] for s in premise_words]).cuda()\n",
    "    hypothesis_idx = torch.tensor([[corpus_vocab.get(w, 3) for w in s] for s in hypothesis_words]).cuda()\n",
    "\n",
    "    c_prem = autoencoder.encode(premise_idx, premise_length, noise=False)\n",
    "    z_prem = inverter(c_prem).detach()\n",
    "\n",
    "#     c_hypo = autoencoder.encode(hypothesis_idx, hypothesis_length, noise=False).detach()\n",
    "#     c_hypo.requires_grad = True\n",
    "    c_hypo = autoencoder.encode(hypothesis_idx, hypothesis_length, noise=False)\n",
    "    z_hypo = inverter(c_hypo)\n",
    "    \n",
    "    premise = premise.unsqueeze(0)\n",
    "    hypothesis = hypothesis.unsqueeze(0)\n",
    "    target = target.unsqueeze(0)\n",
    "\n",
    "    mlp_classifier.zero_grad()\n",
    "    inverter.zero_grad()\n",
    "    \n",
    "    #temp = torch.Tensor(1, 300).fill_(0).cuda().detach()\n",
    "    for j in range(5):\n",
    "        temp = torch.Tensor(1, 300).normal_(0, 0.1).cuda().detach()\n",
    "        temp.requires_grad=True\n",
    "        c_hypoprime = [{'params': temp}]\n",
    "        optimizer = torch.optim.Adam(c_hypoprime, lr=1e-4)\n",
    "\n",
    "        for i in range(500):\n",
    "            output2 = torch.nn.functional.softmax(classifier1.forward((premise_idx, hypothesis_idx))).detach()\n",
    "            z_hypoprime = inverter(c_hypoprime[0]['params'][0])\n",
    "            output3 = torch.nn.functional.softmax(mlp_classifier(z_prem, z_hypoprime))\n",
    "            loss4 = cross_entropy(output3, output2) + ALPHA * torch.norm(z_hypoprime, p=2)\n",
    "            optimizer.zero_grad()\n",
    "            loss4.backward()\n",
    "            optimizer.step()\n",
    "            print(loss4)\n",
    "        if(j == 0):\n",
    "            bestloss = loss4\n",
    "            bestadv = c_hypoprime\n",
    "        elif(bestloss > loss4):\n",
    "            bestloss = loss4\n",
    "            bestadv = c_hypoprime\n",
    "            \n",
    "    c_hypoprime = bestadv\n",
    "    nhypo_idx = autoencoder.generate(c_hypoprime[0]['params'][0], 10, False)\n",
    "    return nhypo_idx.squeeze(0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_premiseonly(criterion, premise, hypothesis, target, premise_words, hypothesis_words, premise_length, hypothesis_length):\n",
    "    autoencoder.eval()\n",
    "    inverter.eval()\n",
    "    classifier1.eval()\n",
    "    mlp_classifier.eval()\n",
    "\n",
    "    premise_words = [premise_words]\n",
    "    hypothesis_words = [hypothesis_words]\n",
    "    premise_length = [premise_length]\n",
    "    hypothesis_length = [hypothesis_length]\n",
    "\n",
    "\n",
    "    premise_idx = torch.tensor([[corpus_vocab.get(w, 3) for w in s] for s in premise_words]).cuda()\n",
    "    hypothesis_idx = torch.tensor([[corpus_vocab.get(w, 3) for w in s] for s in hypothesis_words]).cuda()\n",
    "\n",
    "    c_prem = autoencoder.encode(premise_idx, premise_length, noise=False)\n",
    "    z_prem = inverter(c_prem).detach()\n",
    "\n",
    "#     c_hypo = autoencoder.encode(hypothesis_idx, hypothesis_length, noise=False).detach()\n",
    "#     c_hypo.requires_grad = True\n",
    "#     c_hypo = autoencoder.encode(hypothesis_idx, hypothesis_length, noise=False)\n",
    "#     z_hypo = inverter(c_hypo)\n",
    "    \n",
    "    premise = premise.unsqueeze(0)\n",
    "    hypothesis = hypothesis.unsqueeze(0)\n",
    "    target = target.unsqueeze(0)\n",
    "\n",
    "#     mlp_classifier.zero_grad()\n",
    "#     inverter.zero_grad()\n",
    "    for j in range(5):\n",
    "        temp = torch.Tensor(1, 300).normal_(0, 0.1).cuda().detach()\n",
    "        temp.requires_grad=True\n",
    "        c_hypoprime = [{'params': temp}]\n",
    "        optimizer = torch.optim.Adam(c_hypoprime, lr=1e-4)\n",
    "        for i in range(500):\n",
    "            objtive = torch.tensor([[0.98, 0.01, 0.01]]).cuda()\n",
    "            hypothesis_idx = autoencoder.generate(c_hypoprime[0]['params'][0], 10, False)\n",
    "            z_hypoprime = inverter(c_hypoprime[0]['params'][0])\n",
    "            output2 = torch.nn.functional.softmax(mlp_classifier(z_prem, z_hypoprime))\n",
    "            loss4 = cross_entropy(output2, objtive)\n",
    "            optimizer.zero_grad()\n",
    "            loss4.backward()\n",
    "            optimizer.step()\n",
    "        if(j == 0):\n",
    "            bestloss = loss4\n",
    "            bestadv = c_hypoprime\n",
    "        elif(bestloss > loss4):\n",
    "            bestloss = loss4\n",
    "            bestadv = c_hypoprime        \n",
    "            \n",
    "    c_hypoprime = bestadv\n",
    "    nhypo_idx = autoencoder.generate(c_hypoprime[0]['params'][0], 10, False)\n",
    "    return nhypo_idx.squeeze(0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximum(array):\n",
    "    a = array[0]\n",
    "    idx = 0\n",
    "    for i in range(1, 3):\n",
    "        if(a < array[i]):\n",
    "            idx = i\n",
    "            a = array[i]\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(1, 300).fill_(0).requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(p, q):\n",
    "    k = torch.log(p / q)\n",
    "    p = p * k\n",
    "    return torch.sum(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0153)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([0.5118122,  0.23435633, 0.25383145])\n",
    "b = torch.tensor([0.51985246, 0.29073852, 0.18940896])\n",
    "print(kl_divergence(b, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import secrets\n",
    "\n",
    "def samples(alist):\n",
    "    secure_random = secrets.SystemRandom()\n",
    "    num_to_select = int(len(alist) / 2)\n",
    "    list_of_random_items = secure_random.sample(alist, num_to_select)\n",
    "    return list_of_random_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/game/.local/lib/python3.6/site-packages/ipykernel_launcher.py:39: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> a woman plays guitar on the beach . <eos>\n",
      "<sos> a woman plays harmonica at a beach luau .\n",
      "<sos> a man outside , shooting . <eos> <eos> <eos>\n",
      "Old  [0.30798134 0.26576054 0.4262581 ]\n",
      "New  [0.5514052  0.23071563 0.21787916]\n",
      "Old Prediction: 2\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.1423)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> two girls waving two fingers . <eos> <pad> <pad>\n",
      "<sos> the girls are twenty <pad> <pad> <pad> <pad> <pad>\n",
      "<sos> there with lots of a sitting . <eos> <eos>\n",
      "Old  [0.43067834 0.2610901  0.30823156]\n",
      "New  [0.3923007  0.08578537 0.52191395]\n",
      "Old Prediction: 0\n",
      "New Prediction: 2\n",
      "similarity: tensor(0.1428)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> a concert outside for good morning america . <eos>\n",
      "<sos> music is playing on good morning america . <pad>\n",
      "<sos> there people are on ocean coming <eos> <eos> <eos>\n",
      "Old  [0.277981   0.40899327 0.31302577]\n",
      "New  [0.5247121  0.15352434 0.3217636 ]\n",
      "Old Prediction: 1\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.1918)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> a man hanging off a partially framed roof .\n",
      "<sos> a man is sitting down . <pad> <pad> <pad>\n",
      "<sos> a very tall crowd are running a concert .\n",
      "Old  [0.38214192 0.120331   0.49752712]\n",
      "New  [0.28134418 0.41327134 0.30538452]\n",
      "Old Prediction: 2\n",
      "New Prediction: 1\n",
      "similarity: tensor(0.2747)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> a group of people are watching the fireworks .\n",
      "<sos> people watch fireworks . <pad> <pad> <pad> <pad> <pad>\n",
      "<sos> there in people outdoors <eos> <eos> <eos> <eos> <eos>\n",
      "Old  [0.605735   0.20508982 0.18917516]\n",
      "New  [0.59045786 0.18582943 0.22371268]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0041)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> men standing outside in front of canadian flag .\n",
      "<sos> men are inside watching tv . <pad> <pad> <pad>\n",
      "<sos> people are standing by pictures <eos> <eos> <eos> <eos>\n",
      "Old  [0.22587107 0.2408007  0.53332824]\n",
      "New  [0.5150128  0.23392063 0.25106654]\n",
      "Old Prediction: 2\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.2285)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> a soccer game is in progress . <eos> <pad>\n",
      "<sos> a <oov> sports event is happening now . <pad>\n",
      "<sos> people in a machine . <eos> <eos> <eos> <eos>\n",
      "Old  [0.386766   0.41070613 0.2025279 ]\n",
      "New  [0.6257335  0.17042257 0.20384392]\n",
      "Old Prediction: 1\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.1525)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> 3 kids running on a red track . <eos>\n",
      "<sos> the kids ran fast on the red track .\n",
      "<sos> nobody giving many a white photo <eos> . <eos>\n",
      "Old  [0.07658096 0.37149557 0.55192345]\n",
      "New  [0.38250843 0.41417566 0.20331585]\n",
      "Old Prediction: 2\n",
      "New Prediction: 1\n",
      "similarity: tensor(0.4572)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> a waitress is taking orders at work . <eos>\n",
      "<sos> a waitress is doing her job . <pad> <pad>\n",
      "<sos> tall dogs wearing gear <eos> <eos> <eos> <eos> <eos>\n",
      "Old  [0.33869624 0.3791049  0.28219882]\n",
      "New  [0.594239   0.21987571 0.18588527]\n",
      "Old Prediction: 1\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.1367)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> a <oov> , tattooed man plays a guitar .\n",
      "<sos> a tattooed man sweats and plays a guitar <pad>\n",
      "<sos> man and pieces of cameras are phone . <eos>\n",
      "Old  [0.38514993 0.22423409 0.390616  ]\n",
      "New  [0.61085695 0.2256625  0.16348049]\n",
      "Old Prediction: 2\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.1408)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> a young woman builds a gingerbread house . <eos>\n",
      "<sos> a man is building a gingerbread house <pad> <pad>\n",
      "<sos> there are two arab men driving <eos> <eos> <eos>\n",
      "Old  [0.4590298  0.20906565 0.33190462]\n",
      "New  [0.45319006 0.21579741 0.33101258]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0001)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> three men sit outside a cafe . <eos> <pad>\n",
      "<sos> outside a cafe , some men sit . <pad>\n",
      "<sos> many building are outside training . <eos> <eos> <eos>\n",
      "Old  [0.4106686  0.1792075  0.41012385]\n",
      "New  [0.46742812 0.32138565 0.21118629]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.1081)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> man drives car next to shipping containers . <eos>\n",
      "<sos> a woman drives a truck past some containers .\n",
      "<sos> a person cooking together <eos> <eos> <eos> <eos> <eos>\n",
      "Old  [0.3905278  0.2282539  0.38121825]\n",
      "New  [0.36975187 0.31194395 0.3183042 ]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0198)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> three people walking up stairs near boat marina .\n",
      "<sos> some people go up stairs . <pad> <pad> <pad>\n",
      "<sos> crowd standing with banners on their heads . <eos>\n",
      "Old  [0.35821113 0.46494904 0.17683983]\n",
      "New  [0.3518708  0.24534059 0.4027886 ]\n",
      "Old Prediction: 1\n",
      "New Prediction: 2\n",
      "similarity: tensor(0.1684)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> 2 kids are jumping on the beach . <eos>\n",
      "<sos> there are 2 children outside . <pad> <pad> <pad>\n",
      "<sos> food is performing with tricks <eos> <eos> <eos> <eos>\n",
      "Old  [0.7065324  0.16089545 0.13257211]\n",
      "New  [0.45048156 0.3063884  0.24313004]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.1421)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> a boy standing on railing <eos> <pad> <pad> <pad>\n",
      "<sos> a boy is skating on a street . <pad>\n",
      "<sos> an person is holding and outdoors <eos> <eos> <eos>\n",
      "Old  [0.3437624  0.2636536  0.39258394]\n",
      "New  [0.64768165 0.18850842 0.16380996]\n",
      "Old Prediction: 2\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.2039)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> an attractive girl sells things to boys . <eos>\n",
      "<sos> the girl is pretty . <pad> <pad> <pad> <pad>\n",
      "<sos> there are two people under on the stairs .\n",
      "Old  [0.36358365 0.2861263  0.35029003]\n",
      "New  [0.4784335  0.191561   0.33000553]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0348)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> a baby , holding a toy , cries .\n",
      "<sos> the baby is a <oov> <pad> <pad> <pad> <pad>\n",
      "<sos> there are people waking some objects . <eos> <eos>\n",
      "Old  [0.32657638 0.31406417 0.3593594 ]\n",
      "New  [0.7040776  0.19961435 0.09630805]\n",
      "Old Prediction: 2\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.3236)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> men in the park . <eos> <pad> <pad> <pad>\n",
      "<sos> men are playing frisbee together while people sunbathe .\n",
      "<sos> people are standing outdoors holding . <eos> <eos> <eos>\n",
      "Old  [0.55443156 0.2782535  0.16731492]\n",
      "New  [0.69203377 0.09414399 0.21382225]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.1038)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> several kids playing in an outdoor water fountain .\n",
      "<sos> two children play on a slide . <pad> <pad>\n",
      "<sos> people sits with sign . <eos> <eos> <eos> cooking\n",
      "Old  [0.33004677 0.2902902  0.37966302]\n",
      "New  [0.45399538 0.14220801 0.40379655]\n",
      "Old Prediction: 2\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0682)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> a little girl is using the vacuum cleaner .\n",
      "<sos> the little girl is doing nothing . <pad> <pad>\n",
      "<sos> there are guys wearing outdoors . <eos> <eos> <eos>\n",
      "Old  [0.28412512 0.30688608 0.40898883]\n",
      "New  [0.68744886 0.17245603 0.14009508]\n",
      "Old Prediction: 2\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.3579)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> an elderly woman cleans fish outdoors . <eos> <pad>\n",
      "<sos> a woman is cleaning a bass <pad> <pad> <pad>\n",
      "<sos> three people and another talk . <eos> <eos> <eos>\n",
      "Old  [0.42135832 0.23620681 0.34243488]\n",
      "New  [0.41474202 0.32472476 0.26053318]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0256)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> two guys in front of microphones . <eos> <pad>\n",
      "<sos> two men are in front of microphones . <pad>\n",
      "<sos> there group are outside doing activities . <eos> <eos>\n",
      "Old  [0.5637682  0.20375624 0.23247555]\n",
      "New  [0.5945819 0.2285565 0.1768616]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0095)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> a guy with a scarf and woven toboggan .\n",
      "<sos> a young lady in a dress . <pad> <pad>\n",
      "<sos> people playing instruments <oov> and wears <eos> <eos> <eos>\n",
      "Old  [0.39105734 0.271855   0.33708763]\n",
      "New  [0.55804306 0.23474596 0.20721094]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0631)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> a girls is jumping in the sand . <eos>\n",
      "<sos> a girl is sitting in the sand . <pad>\n",
      "<sos> there are animals behind a drawing . <eos> <eos>\n",
      "Old  [0.20457244 0.13908385 0.6563437 ]\n",
      "New  [0.6379066  0.14980009 0.2122933 ]\n",
      "Old Prediction: 2\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.4970)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> men fighting in front of a bar . <eos>\n",
      "<sos> they are fighting in a boxing ring . <pad>\n",
      "<sos> people are playing along live <eos> <eos> <eos> people\n",
      "Old  [0.11490432 0.45096514 0.43413052]\n",
      "New  [0.57313555 0.23055735 0.19630711]\n",
      "Old Prediction: 1\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.6106)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> a black dog sits on the floor . <eos>\n",
      "<sos> a white dog stands on the couch . <pad>\n",
      "<sos> someone is enjoying with <eos> <eos> <eos> <eos> <eos>\n",
      "Old  [0.1711847  0.17021489 0.6586004 ]\n",
      "New  [0.52920383 0.30931398 0.16148219]\n",
      "Old Prediction: 2\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.5550)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> a man playing an instrument . <eos> <pad> <pad>\n",
      "<sos> the man is doing nothing <pad> <pad> <pad> <pad>\n",
      "<sos> a person is with some items . <eos> <eos>\n",
      "Old  [0.36024487 0.25910455 0.38065055]\n",
      "New  [0.6620083 0.2123513 0.1256404]\n",
      "Old Prediction: 2\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.2213)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> construction workers are working on a construction project .\n",
      "<sos> the workers were replacing windows . <pad> <pad> <pad>\n",
      "<sos> three men and dog are outside carrying bags .\n",
      "Old  [0.38776383 0.29419845 0.31803778]\n",
      "New  [0.63187087 0.1353913  0.23273785]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.1308)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> woman stopping to smell the flowers . <eos> <pad>\n",
      "<sos> the man stopped to smell the flowers . <pad>\n",
      "<sos> children are with adults playing sports <eos> <eos> <eos>\n",
      "Old  [0.13195127 0.51191944 0.3561293 ]\n",
      "New  [0.5757757  0.18810157 0.23612273]\n",
      "Old Prediction: 1\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.5629)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> kids riding the subway <eos> <pad> <pad> <pad> <pad>\n",
      "<sos> kids are in a truck <pad> <pad> <pad> <pad>\n",
      "<sos> people are sunbathing by the environment . <eos> <eos>\n",
      "Old  [0.5562502 0.1686459 0.2751039]\n",
      "New  [0.43484956 0.3046029  0.26054755]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0589)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> four skiers climbing snow <oov> mountain . <eos> <pad>\n",
      "<sos> skier got stuck in a tree <pad> <pad> <pad>\n",
      "<sos> there are dark outside climbing . <eos> <eos> <eos>\n",
      "Old  [0.25395805 0.28312597 0.462916  ]\n",
      "New  [0.48236123 0.23102051 0.2866183 ]\n",
      "Old Prediction: 2\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.1251)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> men flee a bull during a <oov> competition .\n",
      "<sos> a bull chases some men . <pad> <pad> <pad>\n",
      "<sos> there is many people reading . <eos> <eos> <eos>\n",
      "Old  [0.40240282 0.30789718 0.28970006]\n",
      "New  [0.5674724  0.1796845  0.25284305]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0639)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> two friends hold trophies . <eos> <pad> <pad> <pad>\n",
      "<sos> a person rides a bicycle alone . <pad> <pad>\n",
      "<sos> group of people in a match . <eos> <eos>\n",
      "Old  [0.35826868 0.14970051 0.49203083]\n",
      "New  [0.4203219  0.29753834 0.28213972]\n",
      "Old Prediction: 2\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.1146)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> a bee sits on a flower . <eos> <pad>\n",
      "<sos> a bee flies into a <oov> . <pad> <pad>\n",
      "<sos> someone is sleeping with sitting <eos> <eos> <eos> <eos>\n",
      "Old  [0.3150794  0.3396014  0.34531918]\n",
      "New  [0.2541788  0.08869678 0.65712446]\n",
      "Old Prediction: 2\n",
      "New Prediction: 2\n",
      "similarity: tensor(0.2491)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> a dog on a beach dragging an item <eos>\n",
      "<sos> a dog is dragging something along a beach .\n",
      "<sos> this man is resting by <eos> <eos> <eos> <eos>\n",
      "Old  [0.45044115 0.26488835 0.28467053]\n",
      "New  [0.35417256 0.30813128 0.33769622]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0191)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> road workers among piles of debris . <eos> <pad>\n",
      "<sos> the road workers made piles of debris . <pad>\n",
      "<sos> people are gathered on large street outdoors . <eos>\n",
      "Old  [0.26815787 0.36521128 0.36663082]\n",
      "New  [0.6418439  0.18196486 0.17619121]\n",
      "Old Prediction: 2\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.3043)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> a man in a red coat skiing . <eos>\n",
      "<sos> a man skis outdoors . <pad> <pad> <pad> <pad>\n",
      "<sos> this is made by people . <eos> <eos> <eos>\n",
      "Old  [0.57877666 0.23415874 0.18706463]\n",
      "New  [0.49789414 0.36831367 0.1337921 ]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0470)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> a firefighter is working at a fire . <eos>\n",
      "<sos> a firefighter is at home with the flu .\n",
      "<sos> people are standing and in line . <eos> <eos>\n",
      "Old  [0.15168457 0.3804796  0.46783578]\n",
      "New  [0.6332669  0.13002504 0.236708  ]\n",
      "Old Prediction: 2\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.6041)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> a dog trying to catch a ball . <eos>\n",
      "<sos> the animal is playing with a ball . <pad>\n",
      "<sos> there are people are near a umbrella . <eos>\n",
      "Old  [0.44583583 0.2298309  0.3243333 ]\n",
      "New  [0.8657666  0.06288232 0.07135106]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.3850)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> a woman is reading with a child . <eos>\n",
      "<sos> a woman is with a child <pad> <pad> <pad>\n",
      "<sos> this man is laying next to pipes . <eos>\n",
      "Old  [0.5817873  0.21510166 0.20311108]\n",
      "New  [0.38533336 0.28722212 0.32744452]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0807)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> two black dogs are running on pavement <eos> <pad>\n",
      "<sos> two puppies are running on pavement <pad> <pad> <pad>\n",
      "<sos> there people are celebrating the stands outside <eos> <eos>\n",
      "Old  [0.3991844  0.20125546 0.39956018]\n",
      "New  [0.52148896 0.21481103 0.2637    ]\n",
      "Old Prediction: 2\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0438)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> a boy gets ready to shoot a basketball .\n",
      "<sos> there is a child in this picture <pad> <pad>\n",
      "<sos> a family gathers water in a bench . <eos>\n",
      "Old  [0.70353323 0.11508659 0.18138012]\n",
      "New  [0.4363544  0.19406454 0.369581  ]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.1560)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> two men in black running in a race .\n",
      "<sos> two men are running together <pad> <pad> <pad> <pad>\n",
      "<sos> people are indoors <oov> outdoors . <eos> <eos> kids\n",
      "Old  [0.51826394 0.23838794 0.24334814]\n",
      "New  [0.6454971  0.23333472 0.12116823]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0522)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> three people at are doing <oov> work . <eos>\n",
      "<sos> the work is risky . <pad> <pad> <pad> <pad>\n",
      "<sos> cops crossing a beautiful street . <eos> . <eos>\n",
      "Old  [0.28775033 0.360448   0.3518017 ]\n",
      "New  [0.26363775 0.32788563 0.40847662]\n",
      "Old Prediction: 1\n",
      "New Prediction: 2\n",
      "similarity: tensor(0.0069)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> a man in green pants on a bicycle .\n",
      "<sos> a man is on his way to work .\n",
      "<sos> there is a asian in boy clothing . <eos>\n",
      "Old  [0.16737197 0.65346396 0.17916407]\n",
      "New  [0.61306995 0.20697401 0.17995599]\n",
      "Old Prediction: 1\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.5588)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> a child is standing on her head . <eos>\n",
      "<sos> the child is wearing a white shirt . <pad>\n",
      "<sos> there is people painting home . <eos> <eos> <eos>\n",
      "Old  [0.31799015 0.3318709  0.35013893]\n",
      "New  [0.47977376 0.2641276  0.25609866]\n",
      "Old Prediction: 2\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0569)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> six kids splash in water <eos> <pad> <pad> <pad>\n",
      "<sos> kids are in water . <pad> <pad> <pad> <pad>\n",
      "<sos> a few animals are a outside <eos> <eos> <eos>\n",
      "Old  [0.6363065  0.17747147 0.18622199]\n",
      "New  [0.5023733  0.27543104 0.22219566]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0416)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> a man hangs up unusually decorated lamps . <eos>\n",
      "<sos> unusual lamps being hung up by a man <pad>\n",
      "<sos> people are surrounded by trash this . <eos> <eos>\n",
      "Old  [0.44125652 0.29614452 0.2625989 ]\n",
      "New  [0.5269074  0.24962063 0.22347203]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0148)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> man about to kick football on a field .\n",
      "<sos> the man is at home sleeping <pad> <pad> <pad>\n",
      "<sos> people dancing in stage store . <eos> the people\n",
      "Old  [0.11818311 0.14022085 0.74159604]\n",
      "New  [0.5746137  0.16147746 0.26390886]\n",
      "Old Prediction: 2\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.6589)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> colorful glassware for sale by an outdoor vendor .\n",
      "<sos> a vendor is showcasing his glassware collection to passerby\n",
      "<sos> multiple people are crowded fireworks . <eos> <eos> kids\n",
      "Old  [0.19264947 0.52633005 0.28102052]\n",
      "New  [0.6479264  0.20951964 0.14255404]\n",
      "Old Prediction: 1\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.4961)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> a closeup of a very excited young boy .\n",
      "<sos> a picture of a young kid shows their excitement\n",
      "<sos> groups of folks are sleeping in a chair <eos>\n",
      "Old  [0.27644143 0.47069353 0.252865  ]\n",
      "New  [0.2666563  0.08461087 0.64873284]\n",
      "Old Prediction: 1\n",
      "New Prediction: 2\n",
      "similarity: tensor(0.4564)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> two women in costume preparing each others makeup <eos>\n",
      "<sos> men prepare to sing . <pad> <pad> <pad> <pad>\n",
      "<sos> a human is wearing a table . <eos> <eos>\n",
      "Old  [0.36711285 0.46440288 0.16848432]\n",
      "New  [0.45010602 0.23132692 0.3185671 ]\n",
      "Old Prediction: 1\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.1334)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> a black dog is playing inside the fence .\n",
      "<sos> a black female dog is playing . <pad> <pad>\n",
      "<sos> people crossing an outdoors nearby . <eos> <eos> <eos>\n",
      "Old  [0.36759755 0.30510265 0.3272998 ]\n",
      "New  [0.56230956 0.27269623 0.16499418]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0954)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> asian woman in traditional dress and white fur collar\n",
      "<sos> an asian woman is <oov> up nicely . <pad>\n",
      "<sos> street working in background street artist <eos> <eos> <eos>\n",
      "Old  [0.354089   0.37614727 0.2697637 ]\n",
      "New  [0.6492292  0.11768108 0.2330897 ]\n",
      "Old Prediction: 1\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.2228)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> father is pushing his son on the track .\n",
      "<sos> a father and son are on a track <pad>\n",
      "<sos> there is a fancy tables <eos> <eos> <eos> <eos>\n",
      "Old  [0.27268168 0.41874316 0.30857512]\n",
      "New  [0.56350976 0.2078055  0.22868475]\n",
      "Old Prediction: 1\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.1949)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> a young man asleep on the job . <eos>\n",
      "<sos> a young man is sleepin <pad> <pad> <pad> <pad>\n",
      "<sos> children hang outside on <eos> <eos> <eos> <eos> clothing\n",
      "Old  [0.6016021  0.19585606 0.20254192]\n",
      "New  [0.7229726  0.15075363 0.1262738 ]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0337)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-1a7283275a2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moutputarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mnh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperturb_premiseonly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Target '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-8fb2c8efad27>\u001b[0m in \u001b[0;36mperturb_premiseonly\u001b[0;34m(criterion, premise, hypothesis, target, premise_words, hypothesis_words, premise_length, hypothesis_length)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_hypoprime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mobjtive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.98\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mhypothesis_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_hypoprime\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mz_hypoprime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_hypoprime\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "niter = 0\n",
    "\n",
    "idx2words = dict(map(lambda x: (x[1], x[0]), corpus_vocab.items()))\n",
    "oldcorrect = 0\n",
    "newcorrect = 0\n",
    "n = 0\n",
    "alloutputarr = []\n",
    "while niter < len(testloader):\n",
    "    niter += 1\n",
    "    batch = train_iter.next()\n",
    "    for p, h, t, pw, hw, pl, hl in zip(*batch):\n",
    "        outputarr = []\n",
    "        nh = perturb_premiseonly(criterion, p.cuda(), h.cuda(), t.cuda(), pw, hw, pl, hl)\n",
    "        print('--------------------------------')\n",
    "        print('Target ', t)\n",
    "        print(' '.join(pw))\n",
    "        print(' '.join(hw))\n",
    "#         outputarr.append(t)\n",
    "#         outputarr.append(' '.join(pw))\n",
    "#         outputarr.append(' '.join(hw))\n",
    "        nhw = (['<sos>'] + [idx2words[i] for i in nh])[:10]\n",
    "        print(' '.join(nhw))\n",
    "        oldpred = classifier_pred(pw, hw)\n",
    "        newpred = classifier_pred(pw, nhw)\n",
    "        print('Old ', oldpred)\n",
    "        print('New ', newpred)\n",
    "        print('Old Prediction: ' + str(maximum(oldpred)))\n",
    "        print('New Prediction: ' + str(maximum(newpred)))\n",
    "        print('similarity: ' + str(kl_divergence(torch.tensor(newpred), torch.tensor(oldpred))))\n",
    "        if(maximum(oldpred) == t.item()):\n",
    "            oldcorrect = oldcorrect + 1\n",
    "        if(maximum(newpred) == t.item()):\n",
    "            newcorrect = newcorrect + 1\n",
    "        n = n + 1\n",
    "#         outputarr.append(' '.join(nhw))\n",
    "#         outputarr.append(oldpred)\n",
    "#         outputarr.append(newpred)\n",
    "#         outputarr.append(maximum(oldpred))\n",
    "#         outputarr.append(maximum(newpred))\n",
    "#         outputarr.append(kl_divergence(torch.tensor(newpred), torch.tensor(oldpred)))\n",
    "#         alloutputarr.append(outputarr)\n",
    "print('oldcorrect: ' + str(oldcorrect))\n",
    "print('newcorrect: ' + str(newcorrect))\n",
    "print('number of premises ' + str(n))\n",
    "#0 entailment #1 neutral #2 contradiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
