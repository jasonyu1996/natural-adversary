{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "from models import MLPClassifier, Baseline_Embeddings\n",
    "from models import Seq2Seq, MLP_D, MLP_G, MLP_I, MLP_I_AE, JSDistance, Seq2SeqCAE, Baseline_Embeddings, Baseline_LSTM\n",
    "from utils import to_gpu, Corpus, batchify, SNLIDataset, collate_snli\n",
    "import random\n",
    "import pickle as pkl\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original vocab 41574; pruned to 11004\n",
      "Number of sentences dropped from ./data/classifier/train.txt: 448221 out of 549367 total\n",
      "original vocab 41574; pruned to 11004\n",
      "Number of sentences dropped from ./data/classifier/test.txt: 8288 out of 9824 total\n"
     ]
    }
   ],
   "source": [
    "#python3.6 train_surrogate.py --data_path ./data/classifier --save_path game_output/ --classifier_path ./data --load_pretrained .\n",
    "cur_dir = '.'\n",
    "\n",
    "with open(cur_dir + '/vocab.json', 'r') as fin:\n",
    "    corpus_vocab = json.load(fin)\n",
    "\n",
    "corpus_train = SNLIDataset(train=True, vocab_size=11004-4, path='./data/classifier')\n",
    "corpus_test = SNLIDataset(train=False, vocab_size=11004-4, path='./data/classifier')\n",
    "trainloader= torch.utils.data.DataLoader(corpus_train, batch_size = 32, collate_fn=collate_snli, shuffle=True)\n",
    "train_iter = iter(trainloader)\n",
    "testloader= torch.utils.data.DataLoader(corpus_test, batch_size = 32, collate_fn=collate_snli, shuffle=False)\n",
    "random.seed(1111)\n",
    "np.random.seed(1111)\n",
    "torch.manual_seed(1111)\n",
    "\n",
    "EPS = 3e-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/game/.local/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'models.Seq2SeqCAE' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-03683ca3e35d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mautoencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/models/autoencoder_model.pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#gan_gen = torch.load(open(cur_dir + '/models/gan_gen_model.pt', 'rb'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#gan_disc = torch.load(open(cur_dir + '/models/gan_disc_model.pt', 'rb'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/models/inverter_model.pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mroot_key\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 deserialized_objects[root_key] = restore_location(\n\u001b[0;32m--> 505\u001b[0;31m                     data_type(size), location)\n\u001b[0m\u001b[1;32m    506\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mview_metadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_new\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;31m# We need this method only for lazy init, so we can remove it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0m_CudaBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CudaBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "autoencoder = torch.load(open(cur_dir + '/models/autoencoder_model.pt', 'rb'))\n",
    "#gan_gen = torch.load(open(cur_dir + '/models/gan_gen_model.pt', 'rb'))\n",
    "#gan_disc = torch.load(open(cur_dir + '/models/gan_disc_model.pt', 'rb'))\n",
    "inverter = torch.load(open(cur_dir + '/models/inverter_model.pt', 'rb'))\n",
    "\n",
    "classifier1 = Baseline_Embeddings(100, vocab_size=11004)\n",
    "# classifier1 = Baseline_LSTM(100,300,maxlen=10, gpu=args.cuda)\n",
    "\n",
    "classifier1.load_state_dict(torch.load('./models' + \"/baseline/model_emb.pt\"))\n",
    "vocab_classifier1 = pkl.load(open('./models' + \"/vocab.pkl\", 'rb'))\n",
    "\n",
    "mlp_classifier = MLPClassifier(100 * 2, 3, layers='100-50')\n",
    "#if not args.train_mode:\n",
    "mlp_classifier.load_state_dict(torch.load('./surrogate{0}.pt'.format('100-50')))\n",
    "\n",
    "print(classifier1)\n",
    "print(autoencoder)\n",
    "print(inverter)\n",
    "print(mlp_classifier)\n",
    "\n",
    "optimizer = optim.Adam(mlp_classifier.parameters(),\n",
    "                           lr=1e03,\n",
    "                           betas=(0.9, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def evaluate_model():\n",
    "    classifier1.eval()\n",
    "\n",
    "    test_iter = iter(trainloader)\n",
    "    correct=0\n",
    "    total=0\n",
    "    for batch in test_iter:\n",
    "        premise, hypothesis, target, _, _, _, _ = batch\n",
    "\n",
    "        if args.cuda:\n",
    "            premise=premise.cuda()\n",
    "            hypothesis = hypothesis.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        prob_distrib = classifier1.forward((premise, hypothesis))\n",
    "        predictions = np.argmax(prob_distrib.data.cpu().numpy(), 1)\n",
    "        correct+=len(np.where(target.data.cpu().numpy()==predictions)[0])\n",
    "        total+=premise.size(0)\n",
    "    acc=correct/float(total)\n",
    "    print(\"Accuracy:{0}\".format(acc))\n",
    "    return acc\n",
    "\n",
    "autoencoder.gpu = True\n",
    "autoencoder = autoencoder.cuda()\n",
    "autoencoder.start_symbols = autoencoder.start_symbols.cuda()\n",
    "#gan_gen = gan_gen.cuda()\n",
    "#gan_disc = gan_disc.cuda()\n",
    "classifier1 = classifier1.cuda()\n",
    "inverter = inverter.cuda()\n",
    "mlp_classifier = mlp_classifier.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_process(premise, hypothesis, target, premise_words, hypothesis_words, premise_length, hypothesis_length):\n",
    "    #mx = target.max().item()\n",
    "    #assert(mx >= 0 and mx < 3)\n",
    "    #for s, s_w in zip(premise, premise_words):\n",
    "    #    for i, w in zip(s, s_w):\n",
    "    #        assert(corpus_vocab.get(w, 3) == i)\n",
    "    #print(hypothesis_words, flush=True)\n",
    "    autoencoder.eval()\n",
    "    inverter.eval()\n",
    "    classifier1.eval()\n",
    "    mlp_classifier.train()\n",
    "\n",
    "    #print(premise.max().item(), flush=True)\n",
    "    #print(hypothesis.max().item(), flush=True)\n",
    "\n",
    "    premise_idx = torch.tensor([[corpus_vocab.get(w, 3) for w in s] for s in premise_words]).cuda()\n",
    "    hypothesis_idx = torch.tensor([[corpus_vocab.get(w, 3) for w in s] for s in hypothesis_words]).cuda()\n",
    "\n",
    "    c_prem = autoencoder.encode(premise_idx, premise_length, noise=False)\n",
    "    z_prem = inverter(c_prem).detach()\n",
    "\n",
    "    c_hypo = autoencoder.encode(hypothesis_idx, hypothesis_length, noise=False)\n",
    "    z_hypo = inverter(c_hypo).detach()\n",
    "\n",
    "    # z_comb = nn.cat((z_prem, z_hypo), 0).detach()\n",
    "\n",
    "    output = mlp_classifier(z_prem, z_hypo)\n",
    "    gold = classifier1((premise, hypothesis)).detach()\n",
    "\n",
    "    #print(output.shape, flush=True)\n",
    "    #print(gold.shape, flush=True)\n",
    "\n",
    "    acc = (torch.argmax(gold, 1) == target).to(torch.float32).mean().item()\n",
    "    acc_surrogate = (torch.argmax(output, 1) == target).to(torch.float32).mean().item()\n",
    "\n",
    "\n",
    "    loss = -torch.mean(torch.sum(output * F.softmax(gold, dim=1), 1), 0)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item(), acc, acc_surrogate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_pred(pw, hw):\n",
    "    classifier1.eval()\n",
    "\n",
    "    premise_idx = torch.tensor([vocab_classifier1.get(w, 3) for w in pw]).cuda().unsqueeze(0)\n",
    "    hypothesis_idx = torch.tensor([vocab_classifier1.get(w, 3) for w in hw]).cuda().unsqueeze(0)\n",
    "\n",
    "    return F.softmax(classifier1((premise_idx, hypothesis_idx)), 1).squeeze(0).cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(p, q):\n",
    "    q = torch.log(q)\n",
    "    a = p * q\n",
    "    a = torch.sum(a)\n",
    "    a = -a\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb(criterion, premise, hypothesis, target, premise_words, hypothesis_words, premise_length, hypothesis_length):\n",
    "    autoencoder.eval()\n",
    "    inverter.eval()\n",
    "    classifier1.eval()\n",
    "    mlp_classifier.eval()\n",
    "\n",
    "    premise_words = [premise_words]\n",
    "    hypothesis_words = [hypothesis_words]\n",
    "    premisea_length = [premise_length]\n",
    "    hypothesis_length = [hypothesis_length]\n",
    "\n",
    "\n",
    "    premise_idx = torch.tensor([[corpus_vocab.get(w, 3) for w in s] for s in premise_words]).cuda()\n",
    "    hypothesis_idx = torch.tensor([[corpus_vocab.get(w, 3) for w in s] for s in hypothesis_words]).cuda()\n",
    "\n",
    "    c_prem = autoencoder.encode(premise_idx, premise_length, noise=False)\n",
    "    z_prem = inverter(c_prem).detach()\n",
    "\n",
    "#     c_hypo = autoencoder.encode(hypothesis_idx, hypothesis_length, noise=False).detach()\n",
    "#     c_hypo.requires_grad = True\n",
    "    c_hypo = autoencoder.encode(hypothesis_idx, hypothesis_length, noise=False)\n",
    "    z_hypo = inverter(c_hypo)\n",
    "    \n",
    "    premise = premise.unsqueeze(0)\n",
    "    hypothesis = hypothesis.unsqueeze(0)\n",
    "    target = target.unsqueeze(0)\n",
    "\n",
    "    mlp_classifier.zero_grad()\n",
    "    inverter.zero_grad()\n",
    "    \n",
    "    #temp = torch.Tensor(1, 300).fill_(0).cuda().detach()\n",
    "    for j in range(5):\n",
    "        temp = torch.Tensor(1, 300).normal_(0, 0.1).cuda().detach()\n",
    "        temp.requires_grad=True\n",
    "        c_hypoprime = [{'params': temp}]\n",
    "        optimizer = torch.optim.Adam(c_hypoprime, lr=1e-4)\n",
    "\n",
    "        for i in range(500):\n",
    "            output2 = torch.nn.functional.softmax(classifier1.forward((premise_idx, hypothesis_idx))).detach()\n",
    "            z_hypoprime = inverter(c_hypoprime[0]['params'][0])\n",
    "            output3 = torch.nn.functional.softmax(mlp_classifier(z_prem, z_hypoprime))\n",
    "            loss4 = cross_entropy(output3, output2) + ALPHA * torch.norm(z_hypoprime, p=2)\n",
    "            optimizer.zero_grad()\n",
    "            loss4.backward()\n",
    "            optimizer.step()\n",
    "        if(j == 0):\n",
    "            bestloss = loss4\n",
    "            bestadv = c_hypoprime\n",
    "        elif(bestloss > loss4):\n",
    "            bestloss = loss4\n",
    "            bestadv = c_hypoprime        \n",
    "            \n",
    "    c_hypoprime = bestadv\n",
    "    nhypo_idx = autoencoder.generate(c_hypoprime[0]['params'][0], 10, False)\n",
    "    return nhypo_idx.squeeze(0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximum(array):\n",
    "    a = array[0]\n",
    "    idx = 0\n",
    "    for i in range(1, 3):\n",
    "        if(a < array[i]):\n",
    "            idx = i\n",
    "            a = array[i]\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(1, 300).fill_(0).requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(p, q):\n",
    "    k = torch.log(p / q)\n",
    "    p = p * k\n",
    "    return torch.sum(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0153)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([0.5118122,  0.23435633, 0.25383145])\n",
    "b = torch.tensor([0.51985246, 0.29073852, 0.18940896])\n",
    "print(kl_divergence(b, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import secrets\n",
    "\n",
    "def samples(alist):\n",
    "    secure_random = secrets.SystemRandom()\n",
    "    num_to_select = int(len(alist) / 2)\n",
    "    list_of_random_items = secure_random.sample(alist, num_to_select)\n",
    "    return list_of_random_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/game/.local/lib/python3.6/site-packages/ipykernel_launcher.py:39: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/game/.local/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> several children are standing near goats . <eos> <pad>\n",
      "<sos> many children are standing . <pad> <pad> <pad> <pad>\n",
      "<sos> people are rafting along outdoors <eos> <eos> <eos> people\n",
      "Old  [0.57700485 0.18577948 0.23721564]\n",
      "New  [0.7036453  0.19632126 0.10003341]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0641)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> boys playing baseball by the water . <eos> <pad>\n",
      "<sos> kids playing together outside . <pad> <pad> <pad> <pad>\n",
      "<sos> three men are sunbathing standing <eos> . <eos> <eos>\n",
      "Old  [0.6392054  0.17891648 0.18187809]\n",
      "New  [0.38597903 0.17196932 0.44205165]\n",
      "Old Prediction: 0\n",
      "New Prediction: 2\n",
      "similarity: tensor(0.1911)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> a girl with long brown hair standing outside .\n",
      "<sos> a person with hair <pad> <pad> <pad> <pad> <pad>\n",
      "<sos> there are many people watching something with . <eos>\n",
      "Old  [0.69285816 0.15054397 0.1565979 ]\n",
      "New  [0.691154   0.18795283 0.12089315]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0087)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> six girls hold a rope in the ocean .\n",
      "<sos> people are somewhere near water . <pad> <pad> <pad>\n",
      "<sos> people chat with a dress cane . <eos> <eos>\n",
      "Old  [0.7775783  0.12593062 0.096491  ]\n",
      "New  [0.51117945 0.26380807 0.22501244]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.1712)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> a woman in a blue dress standing . <eos>\n",
      "<sos> a woman is on her feet . <pad> <pad>\n",
      "<sos> there is many objects on a kitchen table <eos>\n",
      "Old  [0.36334056 0.26100013 0.37565932]\n",
      "New  [0.5827044  0.18157889 0.23571666]\n",
      "Old Prediction: 2\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0995)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> a woman walking and drinking coffee . <eos> <pad>\n",
      "<sos> the girl paid too much for her coffee .\n",
      "<sos> multiple people are killing people play a cricket .\n",
      "Old  [0.06547382 0.77270377 0.16182245]\n",
      "New  [0.6225725  0.25543323 0.12199431]\n",
      "Old Prediction: 1\n",
      "New Prediction: 0\n",
      "similarity: tensor(1.0849)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> a man walking down an alleyway <eos> <pad> <pad>\n",
      "<sos> the man is a police officer . <pad> <pad>\n",
      "<sos> there were during the beach with <eos> . <eos>\n",
      "Old  [0.3089929  0.368217   0.32279018]\n",
      "New  [0.3425472  0.35681686 0.300636  ]\n",
      "Old Prediction: 1\n",
      "New Prediction: 1\n",
      "similarity: tensor(0.0027)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> a man carries a surfboard at the beach .\n",
      "<sos> a guy is sitting on a couch . <pad>\n",
      "<sos> a girl is sitting at her backyard <eos> .\n",
      "Old  [0.28087395 0.10239133 0.61673474]\n",
      "New  [0.23503102 0.19630212 0.5686669 ]\n",
      "Old Prediction: 2\n",
      "New Prediction: 2\n",
      "similarity: tensor(0.0397)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> a child holding some shoes . <eos> <pad> <pad>\n",
      "<sos> the shoes are black and red . <pad> <pad>\n",
      "<sos> people standing in this lounge <eos> <eos> <eos> <eos>\n",
      "Old  [0.2427922  0.32523233 0.43197545]\n",
      "New  [0.41990587 0.1626849  0.41740924]\n",
      "Old Prediction: 2\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.1030)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> a dog running up a sandy hill <eos> <pad>\n",
      "<sos> a dog is running . <pad> <pad> <pad> <pad>\n",
      "<sos> a human is working wearing gloves <eos> <eos> <eos>\n",
      "Old  [0.47821248 0.25527748 0.26651007]\n",
      "New  [0.60874295 0.24861027 0.14264679]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0512)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> elderly men visit at a pizza shop . <eos>\n",
      "<sos> men visit their favorite store <pad> <pad> <pad> <pad>\n",
      "<sos> there are people filling outdoors . <eos> <eos> <eos>\n",
      "Old  [0.24353622 0.5010276  0.25543612]\n",
      "New  [0.6559717  0.17822123 0.16580716]\n",
      "Old Prediction: 1\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.3941)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> two women at a party having a conversation .\n",
      "<sos> women standing in line at bank . <pad> <pad>\n",
      "<sos> there are people in water . <eos> <eos> <eos>\n",
      "Old  [0.4684748  0.13193937 0.3995858 ]\n",
      "New  [0.6934228  0.12777267 0.17880458]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.1240)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> a <oov> , tattooed man plays a guitar .\n",
      "<sos> a man is playing beatles songs . <pad> <pad>\n",
      "<sos> people are partying with racing . <eos> <eos> man\n",
      "Old  [0.47094426 0.27010724 0.2589485 ]\n",
      "New  [0.600517   0.20738077 0.19210227]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0338)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> young women in dresses standing on a stage <eos>\n",
      "<sos> the women are performers . <pad> <pad> <pad> <pad>\n",
      "<sos> children gather people are living room . <eos> <eos>\n",
      "Old  [0.41851854 0.3521005  0.22938098]\n",
      "New  [0.55133885 0.2514661  0.19719504]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0375)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> eastern dancers holding flags . <eos> <pad> <pad> <pad>\n",
      "<sos> dancers holding flags . <pad> <pad> <pad> <pad> <pad>\n",
      "<sos> there are people outside , a coffee <eos> .\n",
      "Old  [0.6627009  0.13794704 0.19935209]\n",
      "New  [0.58333653 0.20631732 0.21034615]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0199)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> two women in print dresses are walking together .\n",
      "<sos> women are walking on easter sunday . <pad> <pad>\n",
      "<sos> kids practice to be some listening to dance .\n",
      "Old  [0.3898072  0.25298408 0.3572087 ]\n",
      "New  [0.1570689  0.76916385 0.0737673 ]\n",
      "Old Prediction: 0\n",
      "New Prediction: 1\n",
      "similarity: tensor(0.5962)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> an old man sitting in a restaurant . <eos>\n",
      "<sos> there is a man indoors . <pad> <pad> <pad>\n",
      "<sos> a gentleman <oov> baby in a restaurant <eos> <eos>\n",
      "Old  [0.56506944 0.20382814 0.23110247]\n",
      "New  [0.25399488 0.28503454 0.46097058]\n",
      "Old Prediction: 0\n",
      "New Prediction: 2\n",
      "similarity: tensor(0.2108)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> two men are sitting behind a vegetable stall .\n",
      "<sos> the men sat behind the stall . <pad> <pad>\n",
      "<sos> there are people hiking vehicles . <eos> <eos> <eos>\n",
      "Old  [0.18061921 0.24037378 0.57900697]\n",
      "New  [0.5341734  0.2662402  0.19958636]\n",
      "Old Prediction: 2\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.3939)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> two german shepherds playing with a stick . <eos>\n",
      "<sos> the dogs are training . <pad> <pad> <pad> <pad>\n",
      "<sos> people in drag shirt and biking <eos> <eos> stairs\n",
      "Old  [0.39860702 0.3523611  0.2490319 ]\n",
      "New  [0.469199   0.25229344 0.2785076 ]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0234)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> a black dog is running on water . <eos>\n",
      "<sos> the dog is white <pad> <pad> <pad> <pad> <pad>\n",
      "<sos> there of people are pictured . <eos> <eos> the\n",
      "Old  [0.43277627 0.2887322  0.27849153]\n",
      "New  [0.52430266 0.27840498 0.19729237]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0224)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> a woman runs outside in a blue coat .\n",
      "<sos> a woman is inside <pad> <pad> <pad> <pad> <pad>\n",
      "<sos> two firemen are driving with . <eos> <eos> <eos>\n",
      "Old  [0.56437653 0.1948151  0.24080837]\n",
      "New  [0.46262413 0.2570978  0.28027803]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0219)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> officer in riot gear observes demonstration . <eos> <pad>\n",
      "<sos> the officer is a former marine <pad> <pad> <pad>\n",
      "<sos> there are people socializing in a circle . <eos>\n",
      "Old  [0.31573865 0.32960728 0.3546541 ]\n",
      "New  [0.6472129  0.14730944 0.20547768]\n",
      "Old Prediction: 2\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.2338)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> a skateboarder uses a ramp . <eos> <pad> <pad>\n",
      "<sos> a skateboarder skates down a crazy ramp . <pad>\n",
      "<sos> many women going to clear with items . <eos>\n",
      "Old  [0.23776995 0.335503   0.426727  ]\n",
      "New  [0.4747991  0.38284552 0.14235532]\n",
      "Old Prediction: 2\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.2226)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> person with a backpack in a field <eos> <pad>\n",
      "<sos> a person with a backpack walking outside . <pad>\n",
      "<sos> protesters are being paid a run <eos> <eos> <eos>\n",
      "Old  [0.62612414 0.14166982 0.23220603]\n",
      "New  [0.2461255  0.51649404 0.23738043]\n",
      "Old Prediction: 0\n",
      "New Prediction: 1\n",
      "similarity: tensor(0.4435)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> women wearing sunglasses shopping downtown . <eos> <pad> <pad>\n",
      "<sos> a woman in sunglasses is shopping . <pad> <pad>\n",
      "<sos> people are bathing some street vendors . <eos> <eos>\n",
      "Old  [0.32006347 0.23239294 0.44754365]\n",
      "New  [0.50220287 0.29356474 0.20423241]\n",
      "Old Prediction: 2\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.1346)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> a group of people demonstrating . <eos> <pad> <pad>\n",
      "<sos> a group of people are sleeping . <pad> <pad>\n",
      "<sos> a youth tournament player fighting over <eos> . <eos>\n",
      "Old  [0.3475254  0.16046871 0.49200588]\n",
      "New  [0.1516326  0.4901128  0.35825467]\n",
      "Old Prediction: 2\n",
      "New Prediction: 1\n",
      "similarity: tensor(0.3078)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> many men sit and share a meal together .\n",
      "<sos> women cook together . <pad> <pad> <pad> <pad> <pad>\n",
      "<sos> two street performers are being outside . <eos> <eos>\n",
      "Old  [0.50531477 0.27717024 0.21751495]\n",
      "New  [0.5196517  0.24355201 0.23679626]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0032)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> a young man sprinting very quickly . <eos> <pad>\n",
      "<sos> a man is in a race . <pad> <pad>\n",
      "<sos> there is many people nearby playing a table <eos>\n",
      "Old  [0.38998112 0.27620173 0.33381715]\n",
      "New  [0.6515948  0.15099354 0.19741167]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.1396)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> couple having cocktails at a club . <eos> <pad>\n",
      "<sos> a couple are having drinks . <pad> <pad> <pad>\n",
      "<sos> peoples are bored with cake <eos> <eos> <eos> <eos>\n",
      "Old  [0.49711972 0.2589777  0.24390255]\n",
      "New  [0.3970547  0.3213928  0.28155252]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0206)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> two black dogs chase each other on grass .\n",
      "<sos> black dogs chase each other on grass . <pad>\n",
      "<sos> two man is trying to get a cake .\n",
      "Old  [0.33798185 0.29999414 0.36202404]\n",
      "New  [0.15385656 0.70167315 0.14447026]\n",
      "Old Prediction: 2\n",
      "New Prediction: 1\n",
      "similarity: tensor(0.3424)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> an outside market is packed with people . <eos>\n",
      "<sos> the market is empty <pad> <pad> <pad> <pad> <pad>\n",
      "<sos> people are writing songs in . <eos> <eos> <eos>\n",
      "Old  [0.36750758 0.21415918 0.41833323]\n",
      "New  [0.46808973 0.2581174  0.2737929 ]\n",
      "Old Prediction: 2\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0454)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> a young couple embracing in a train station .\n",
      "<sos> two people are at a train station <pad> <pad>\n",
      "<sos> the married couple shows off their having a <oov>\n",
      "Old  [0.5095104  0.25436857 0.23612101]\n",
      "New  [0.07691163 0.66861415 0.25447425]\n",
      "Old Prediction: 0\n",
      "New Prediction: 1\n",
      "similarity: tensor(0.5198)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> a pitcher throws the ball . <eos> <pad> <pad>\n",
      "<sos> the man is driving a speedboat . <pad> <pad>\n",
      "<sos> nobody is wearing anything of <eos> <eos> <eos> <eos>\n",
      "Old  [0.33316496 0.21904531 0.44778973]\n",
      "New  [0.5199486  0.25323468 0.22681676]\n",
      "Old Prediction: 2\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.1139)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> man in a rice field wearing shorts . <eos>\n",
      "<sos> a man is in a cafeteria . <pad> <pad>\n",
      "<sos> guy with sports shirt <eos> <eos> <eos> <eos> clothing\n",
      "Old  [0.35025784 0.29379296 0.35594913]\n",
      "New  [0.5545874  0.27375227 0.17166027]\n",
      "Old Prediction: 2\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.1103)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> a group of kids standing outside . <eos> <pad>\n",
      "<sos> kids are standing outside waiting for the bus .\n",
      "<sos> an individual working together in the park <eos> <eos>\n",
      "Old  [0.1931964  0.34944773 0.45735592]\n",
      "New  [0.20510168 0.33399624 0.4609021 ]\n",
      "Old Prediction: 2\n",
      "New Prediction: 2\n",
      "similarity: tensor(0.0007)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> man and a woman standing outside . <eos> <pad>\n",
      "<sos> the couple is viewing a sunset . <pad> <pad>\n",
      "<sos> cops are pushing a child outside <eos> . <eos>\n",
      "Old  [0.31421447 0.4080735  0.27771205]\n",
      "New  [0.4988878  0.21828358 0.28282863]\n",
      "Old Prediction: 1\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0992)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> a large gathering of people partying on boats .\n",
      "<sos> the boats are sinking . <pad> <pad> <pad> <pad>\n",
      "<sos> a person 's an airplane with items . <eos>\n",
      "Old  [0.30371472 0.2706828  0.4256025 ]\n",
      "New  [0.37594754 0.23313664 0.39091584]\n",
      "Old Prediction: 2\n",
      "New Prediction: 2\n",
      "similarity: tensor(0.0122)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> <oov> children dig holes in the dirt . <eos>\n",
      "<sos> two children eat pasta while partying . <pad> <pad>\n",
      "<sos> people are holding on . <eos> <eos> <eos> man\n",
      "Old  [0.35696664 0.38187066 0.26116273]\n",
      "New  [0.65599877 0.16288441 0.18111686]\n",
      "Old Prediction: 1\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.1941)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> two people grocery shopping at walmart . <eos> <pad>\n",
      "<sos> two <oov> <oov> out potential kills in walmart .\n",
      "<sos> the girl is bike sitting at the lake .\n",
      "Old  [0.20995064 0.37850142 0.41154793]\n",
      "New  [0.06605234 0.16211122 0.77183646]\n",
      "Old Prediction: 2\n",
      "New Prediction: 2\n",
      "similarity: tensor(0.2715)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> potential customers shopping in a busy marketplace . <eos>\n",
      "<sos> some humans shopping . <pad> <pad> <pad> <pad> <pad>\n",
      "<sos> people are surrounded by . <eos> <eos> <eos> party\n",
      "Old  [0.60459244 0.23852028 0.15688728]\n",
      "New  [0.59777087 0.243184   0.15904512]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(9.8679e-05)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> the water is very clear . <eos> <pad> <pad>\n",
      "<sos> the water is clear . <pad> <pad> <pad> <pad>\n",
      "<sos> peoples is playing tug-of-war <eos> <eos> <eos> <eos> clothing\n",
      "Old  [0.49166244 0.24459052 0.26374698]\n",
      "New  [0.50330734 0.25601953 0.24067315]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0014)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> two young children play with colored balls . <eos>\n",
      "<sos> the children are having fun together . <pad> <pad>\n",
      "<sos> there person outside of a restaurant . <eos> <eos>\n",
      "Old  [0.30948555 0.46325386 0.22726056]\n",
      "New  [0.52503866 0.18420601 0.29075536]\n",
      "Old Prediction: 1\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.1793)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> two boys play in a park fountain . <eos>\n",
      "<sos> the boys do n't have on any shoes .\n",
      "<sos> two basketball are getting ready to medical themselves .\n",
      "Old  [0.21017714 0.52802426 0.26179865]\n",
      "New  [0.13145828 0.6666868  0.20185491]\n",
      "Old Prediction: 1\n",
      "New Prediction: 1\n",
      "similarity: tensor(0.0413)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> a woman examines a specimen using a microscope .\n",
      "<sos> a woman is examining a <oov> <pad> <pad> <pad>\n",
      "<sos> a man is clean outside the cage <eos> <eos>\n",
      "Old  [0.4111777  0.22644122 0.36238107]\n",
      "New  [0.28554267 0.26703805 0.44741926]\n",
      "Old Prediction: 0\n",
      "New Prediction: 2\n",
      "similarity: tensor(0.0342)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> workers standing in a work zone . <eos> <pad>\n",
      "<sos> workers are standing around <pad> <pad> <pad> <pad> <pad>\n",
      "<sos> there people with ice cream outside <eos> . <eos>\n",
      "Old  [0.69857925 0.10038471 0.20103596]\n",
      "New  [0.6097728  0.18732326 0.20290396]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0358)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> a brown horse jumps through its <oov> . <eos>\n",
      "<sos> the horse is green <pad> <pad> <pad> <pad> <pad>\n",
      "<sos> she is outdoors near some trees . <eos> <eos>\n",
      "Old  [0.44737175 0.23203845 0.32058978]\n",
      "New  [0.5341172  0.33537075 0.13051206]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.1009)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> cycling team standing around in sunny tropical area <eos>\n",
      "<sos> there is more than one person standing outside <pad>\n",
      "<sos> people riding a listening to work in their uniforms\n",
      "Old  [0.7292848  0.11679964 0.15391555]\n",
      "New  [0.18726167 0.5690756  0.24366274]\n",
      "Old Prediction: 0\n",
      "New Prediction: 1\n",
      "similarity: tensor(0.7585)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> a bike jumps through the air . <eos> <pad>\n",
      "<sos> a bike in mid-air . <pad> <pad> <pad> <pad>\n",
      "<sos> there dog jumps of not standing <eos> <eos> <eos>\n",
      "Old  [0.47740084 0.24243613 0.28016296]\n",
      "New  [0.391508   0.15036704 0.45812503]\n",
      "Old Prediction: 0\n",
      "New Prediction: 2\n",
      "similarity: tensor(0.0758)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> a crowd is enjoying an outdoor festival . <eos>\n",
      "<sos> there is a crowd at a music festival .\n",
      "<sos> two men wearing boots on a boat . <eos>\n",
      "Old  [0.5114248  0.32424217 0.16433308]\n",
      "New  [0.37805083 0.213501   0.40844813]\n",
      "Old Prediction: 0\n",
      "New Prediction: 2\n",
      "similarity: tensor(0.1684)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> a chef cooking at a <oov> grill . <eos>\n",
      "<sos> a cook grilling beef at a <oov> grill <pad>\n",
      "<sos> adult are wearing hanging on a road <eos> .\n",
      "Old  [0.16119131 0.4506318  0.38817686]\n",
      "New  [0.47858652 0.15328974 0.36812377]\n",
      "Old Prediction: 1\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.3360)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> a young boy points a toy rifle off-camera .\n",
      "<sos> a boy is holding a toy rifle . <pad>\n",
      "<sos> people are outdoors and drinks <eos> <eos> <eos> <eos>\n",
      "Old  [0.57118416 0.1990266  0.22978923]\n",
      "New  [0.7005126  0.17879836 0.12068906]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0461)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> a young man is riding his blue bike .\n",
      "<sos> the bike is a road bike . <pad> <pad>\n",
      "<sos> men are huddled together at a table <eos> <eos>\n",
      "Old  [0.36174622 0.2902727  0.34798107]\n",
      "New  [0.55011475 0.25266087 0.1972244 ]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0836)\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> a man making fire roasted pizza . <eos> <pad>\n",
      "<sos> a man uses his pizza oven at home .\n",
      "<sos> a parade of people is in painting . <eos>\n",
      "Old  [0.11363745 0.44578546 0.4405771 ]\n",
      "New  [0.5535362  0.20652026 0.23994353]\n",
      "Old Prediction: 1\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.5717)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> two musicians are playing in the beautiful park .\n",
      "<sos> the musicians are in a hall . <pad> <pad>\n",
      "<sos> there are people drag queen bikes . <eos> <eos>\n",
      "Old  [0.36632377 0.28754368 0.34613258]\n",
      "New  [0.53971905 0.23916772 0.22111319]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0660)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> a tennis player winning her first match . <eos>\n",
      "<sos> a hockey player in pink is winning . <pad>\n",
      "<sos> a woman hanging out at a record meat <eos>\n",
      "Old  [0.38967285 0.26743138 0.3428958 ]\n",
      "New  [0.38344586 0.30468136 0.31187284]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0040)\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> two women are standing together smiling . <eos> <pad>\n",
      "<sos> people are together . <pad> <pad> <pad> <pad> <pad>\n",
      "<sos> multiple people are waiting after watching people . <eos>\n",
      "Old  [0.6553533  0.20133112 0.14331554]\n",
      "New  [0.4669656  0.3107772  0.22225721]\n",
      "Old Prediction: 0\n",
      "New Prediction: 0\n",
      "similarity: tensor(0.0742)\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> a muscular black man dancing in short shorts .\n",
      "<sos> the man is at a strip club . <pad>\n",
      "<sos> customers leave after preparing to start pose . <eos>\n",
      "Old  [0.21091387 0.43069586 0.35839033]\n",
      "New  [0.1105727  0.8004278  0.08899955]\n",
      "Old Prediction: 1\n",
      "New Prediction: 1\n",
      "similarity: tensor(0.3007)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "niter = 0\n",
    "\n",
    "idx2words = dict(map(lambda x: (x[1], x[0]), corpus_vocab.items()))\n",
    "oldcorrect = 0\n",
    "newcorrect = 0\n",
    "n = 0\n",
    "alloutputarr = []\n",
    "while niter < len(testloader):\n",
    "    niter += 1\n",
    "    batch = train_iter.next()\n",
    "    for p, h, t, pw, hw, pl, hl in zip(*batch):\n",
    "        outputarr = []\n",
    "        nh = perturb(criterion, p.cuda(), h.cuda(), t.cuda(), pw, hw, pl, hl)\n",
    "        print('--------------------------------')\n",
    "        print('Target ', t)\n",
    "        print(' '.join(pw))\n",
    "        print(' '.join(hw))\n",
    "#         outputarr.append(t)\n",
    "#         outputarr.append(' '.join(pw))\n",
    "#         outputarr.append(' '.join(hw))\n",
    "        nhw = (['<sos>'] + [idx2words[i] for i in nh])[:10]\n",
    "        print(' '.join(nhw))\n",
    "        oldpred = classifier_pred(pw, hw)\n",
    "        newpred = classifier_pred(pw, nhw)\n",
    "        print('Old ', oldpred)\n",
    "        print('New ', newpred)\n",
    "        print('Old Prediction: ' + str(maximum(oldpred)))\n",
    "        print('New Prediction: ' + str(maximum(newpred)))\n",
    "        print('similarity: ' + str(kl_divergence(torch.tensor(newpred), torch.tensor(oldpred))))\n",
    "        if(maximum(oldpred) == t.item()):\n",
    "            oldcorrect = oldcorrect + 1\n",
    "        if(maximum(newpred) == t.item()):\n",
    "            newcorrect = newcorrect + 1\n",
    "        n = n + 1\n",
    "#         outputarr.append(' '.join(nhw))\n",
    "#         outputarr.append(oldpred)\n",
    "#         outputarr.append(newpred)\n",
    "#         outputarr.append(maximum(oldpred))\n",
    "#         outputarr.append(maximum(newpred))\n",
    "#         outputarr.append(kl_divergence(torch.tensor(newpred), torch.tensor(oldpred)))\n",
    "#         alloutputarr.append(outputarr)\n",
    "print('oldcorrect: ' + str(oldcorrect))\n",
    "print('newcorrect: ' + str(newcorrect))\n",
    "print('number of premises ' + str(n))\n",
    "#0 entailment #1 neutral #2 contradiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
