{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "from models import MLPClassifier, Baseline_Embeddings\n",
    "from models import Seq2Seq, MLP_D, MLP_G, MLP_I, MLP_I_AE, JSDistance, Seq2SeqCAE, Baseline_Embeddings, Baseline_LSTM\n",
    "from utils import to_gpu, Corpus, batchify, SNLIDataset, collate_snli\n",
    "import random\n",
    "import pickle as pkl\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original vocab 41574; pruned to 11004\n",
      "Number of sentences dropped from ./data/classifier/train.txt: 448221 out of 549367 total\n",
      "original vocab 41574; pruned to 11004\n",
      "Number of sentences dropped from ./data/classifier/test.txt: 8288 out of 9824 total\n"
     ]
    }
   ],
   "source": [
    "#python3.6 train_surrogate.py --data_path ./data/classifier --save_path game_output/ --classifier_path ./data --load_pretrained .\n",
    "cur_dir = '.'\n",
    "\n",
    "with open(cur_dir + '/vocab.json', 'r') as fin:\n",
    "    corpus_vocab = json.load(fin)\n",
    "\n",
    "corpus_train = SNLIDataset(train=True, vocab_size=11004-4, path='./data/classifier')\n",
    "corpus_test = SNLIDataset(train=False, vocab_size=11004-4, path='./data/classifier')\n",
    "trainloader= torch.utils.data.DataLoader(corpus_train, batch_size = 32, collate_fn=collate_snli, shuffle=True)\n",
    "train_iter = iter(trainloader)\n",
    "testloader= torch.utils.data.DataLoader(corpus_test, batch_size = 32, collate_fn=collate_snli, shuffle=False)\n",
    "random.seed(1111)\n",
    "np.random.seed(1111)\n",
    "torch.manual_seed(1111)\n",
    "\n",
    "EPS = 3e-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline_Embeddings(\n",
      "  (embedding_prem): Embedding(11004, 100)\n",
      "  (embedding_hypo): Embedding(11004, 100)\n",
      "  (linear): Linear(in_features=200, out_features=3, bias=True)\n",
      ")\n",
      "Seq2SeqCAE(\n",
      "  (embedding): Embedding(11004, 300)\n",
      "  (embedding_decoder): Embedding(11004, 300)\n",
      "  (encoder): Sequential(\n",
      "    (layer-1): Conv1d(300, 500, kernel_size=(3,), stride=(1,))\n",
      "    (bn-1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation-1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (layer-2): Conv1d(500, 700, kernel_size=(3,), stride=(2,))\n",
      "    (bn-2): BatchNorm1d(700, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation-2): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (layer-3): Conv1d(700, 1000, kernel_size=(3,), stride=(2,))\n",
      "    (bn-3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation-3): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (linear): Linear(in_features=1000, out_features=300, bias=True)\n",
      "  (decoder): LSTM(600, 300, batch_first=True)\n",
      "  (linear_dec): Linear(in_features=300, out_features=11004, bias=True)\n",
      ")\n",
      "MLP_I(\n",
      "  (layer1): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (bn1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation1): ReLU()\n",
      "  (layer2): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation2): ReLU()\n",
      "  (layer7): Linear(in_features=300, out_features=100, bias=True)\n",
      ")\n",
      "MLPClassifier(\n",
      "  (layers): Sequential(\n",
      "    (layer0): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (bn0): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation0): ReLU()\n",
      "    (layer1): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (bn1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation1): ReLU()\n",
      "  )\n",
      "  (linear): Linear(in_features=50, out_features=3, bias=True)\n",
      "  (log_softmax): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "autoencoder = torch.load(open(cur_dir + '/models/autoencoder_model.pt', 'rb'))\n",
    "#gan_gen = torch.load(open(cur_dir + '/models/gan_gen_model.pt', 'rb'))\n",
    "#gan_disc = torch.load(open(cur_dir + '/models/gan_disc_model.pt', 'rb'))\n",
    "inverter = torch.load(open(cur_dir + '/models/inverter_model.pt', 'rb'))\n",
    "\n",
    "classifier1 = Baseline_Embeddings(100, vocab_size=11004)\n",
    "#classifier1 = Baseline_LSTM(100,300,maxlen=args.maxlen, gpu=args.cuda)\n",
    "classifier1.load_state_dict(torch.load('./models' + \"/baseline/model_emb.pt\"))\n",
    "vocab_classifier1 = pkl.load(open('./models' + \"/vocab.pkl\", 'rb'))\n",
    "\n",
    "mlp_classifier = MLPClassifier(100 * 2, 3, layers='100-50')\n",
    "#if not args.train_mode:\n",
    "mlp_classifier.load_state_dict(torch.load('./surrogate{0}.pt'.format('100-50')))\n",
    "\n",
    "print(classifier1)\n",
    "print(autoencoder)\n",
    "print(inverter)\n",
    "print(mlp_classifier)\n",
    "\n",
    "optimizer = optim.Adam(mlp_classifier.parameters(),\n",
    "                           lr=1e03,\n",
    "                           betas=(0.9, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def evaluate_model():\n",
    "    classifier1.eval()\n",
    "\n",
    "    test_iter = iter(trainloader)\n",
    "    correct=0\n",
    "    total=0\n",
    "    for batch in test_iter:\n",
    "        premise, hypothesis, target, _, _, _, _ = batch\n",
    "\n",
    "        if args.cuda:\n",
    "            premise=premise.cuda()\n",
    "            hypothesis = hypothesis.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        prob_distrib = classifier1.forward((premise, hypothesis))\n",
    "        predictions = np.argmax(prob_distrib.data.cpu().numpy(), 1)\n",
    "        correct+=len(np.where(target.data.cpu().numpy()==predictions)[0])\n",
    "        total+=premise.size(0)\n",
    "    acc=correct/float(total)\n",
    "    print(\"Accuracy:{0}\".format(acc))\n",
    "    return acc\n",
    "\n",
    "autoencoder.gpu = True\n",
    "autoencoder = autoencoder.cuda()\n",
    "autoencoder.start_symbols = autoencoder.start_symbols.cuda()\n",
    "#gan_gen = gan_gen.cuda()\n",
    "#gan_disc = gan_disc.cuda()\n",
    "classifier1 = classifier1.cuda()\n",
    "inverter = inverter.cuda()\n",
    "mlp_classifier = mlp_classifier.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_process(premise, hypothesis, target, premise_words, hypothesis_words, premise_length, hypothesis_length):\n",
    "    #mx = target.max().item()\n",
    "    #assert(mx >= 0 and mx < 3)\n",
    "    #for s, s_w in zip(premise, premise_words):\n",
    "    #    for i, w in zip(s, s_w):\n",
    "    #        assert(corpus_vocab.get(w, 3) == i)\n",
    "    #print(hypothesis_words, flush=True)\n",
    "    autoencoder.eval()\n",
    "    inverter.eval()\n",
    "    classifier1.eval()\n",
    "    mlp_classifier.train()\n",
    "\n",
    "    #print(premise.max().item(), flush=True)\n",
    "    #print(hypothesis.max().item(), flush=True)\n",
    "\n",
    "    premise_idx = torch.tensor([[corpus_vocab.get(w, 3) for w in s] for s in premise_words]).cuda()\n",
    "    hypothesis_idx = torch.tensor([[corpus_vocab.get(w, 3) for w in s] for s in hypothesis_words]).cuda()\n",
    "\n",
    "    c_prem = autoencoder.encode(premise_idx, premise_length, noise=False)\n",
    "    z_prem = inverter(c_prem).detach()\n",
    "\n",
    "    c_hypo = autoencoder.encode(hypothesis_idx, hypothesis_length, noise=False)\n",
    "    z_hypo = inverter(c_hypo).detach()\n",
    "\n",
    "    # z_comb = nn.cat((z_prem, z_hypo), 0).detach()\n",
    "\n",
    "    output = mlp_classifier(z_prem, z_hypo)\n",
    "    gold = classifier1((premise, hypothesis)).detach()\n",
    "\n",
    "    #print(output.shape, flush=True)\n",
    "    #print(gold.shape, flush=True)\n",
    "\n",
    "    acc = (torch.argmax(gold, 1) == target).to(torch.float32).mean().item()\n",
    "    acc_surrogate = (torch.argmax(output, 1) == target).to(torch.float32).mean().item()\n",
    "\n",
    "\n",
    "    loss = -torch.mean(torch.sum(output * F.softmax(gold, dim=1), 1), 0)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item(), acc, acc_surrogate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_pred(pw, hw):\n",
    "    classifier1.eval()\n",
    "\n",
    "    premise_idx = torch.tensor([vocab_classifier1.get(w, 3) for w in pw]).cuda().unsqueeze(0)\n",
    "    hypothesis_idx = torch.tensor([vocab_classifier1.get(w, 3) for w in hw]).cuda().unsqueeze(0)\n",
    "\n",
    "    return F.softmax(classifier1((premise_idx, hypothesis_idx)), 1).squeeze(0).cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(p, q):\n",
    "    q = torch.log(q)\n",
    "    a = p * q\n",
    "    a = torch.sum(a)\n",
    "    a = -a\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb(criterion, premise, hypothesis, target, premise_words, hypothesis_words, premise_length, hypothesis_length):\n",
    "    autoencoder.eval()\n",
    "    inverter.eval()\n",
    "    classifier1.eval()\n",
    "    mlp_classifier.eval()\n",
    "\n",
    "    premise_words = [premise_words]\n",
    "    hypothesis_words = [hypothesis_words]\n",
    "    premisea_length = [premise_length]\n",
    "    hypothesis_length = [hypothesis_length]\n",
    "\n",
    "\n",
    "    premise_idx = torch.tensor([[corpus_vocab.get(w, 3) for w in s] for s in premise_words]).cuda()\n",
    "    hypothesis_idx = torch.tensor([[corpus_vocab.get(w, 3) for w in s] for s in hypothesis_words]).cuda()\n",
    "\n",
    "    c_prem = autoencoder.encode(premise_idx, premise_length, noise=False)\n",
    "    z_prem = inverter(c_prem).detach()\n",
    "\n",
    "    c_hypo = autoencoder.encode(hypothesis_idx, hypothesis_length, noise=False).detach()\n",
    "    c_hypo.requires_grad = True\n",
    "    z_hypo = inverter(c_hypo)\n",
    "    \n",
    "    premise = premise.unsqueeze(0)\n",
    "    hypothesis = hypothesis.unsqueeze(0)\n",
    "    target = target.unsqueeze(0)\n",
    "    \n",
    "#     output = torch.nn.functional.softmax(mlp_classifier(z_prem, z_hypo))\n",
    "#     output2 = torch.nn.functional.softmax(classifier1.forward((premise_idx, hypothesis_idx))).detach()\n",
    "#     print(\"output\")\n",
    "#     print(output)\n",
    "#     print(\"output2\")\n",
    "#     print(output2)\n",
    "\n",
    "#     loss = criterion(output, target)\n",
    "    mlp_classifier.zero_grad()\n",
    "    inverter.zero_grad()\n",
    "#     loss.backward()\n",
    "#     loss2 = criterion(output2, target)\n",
    "\n",
    "#     direction = torch.sign(c_hypo.grad)\n",
    "#     nc_hypo = c_hypo + EPS * direction\n",
    "#     nhypo_idx = autoencoder.generate(nc_hypo, 10, False)\n",
    "#     z_hypoprime = inverter(nc_hypo).detach()\n",
    "\n",
    "#     output3 = torch.nn.functional.softmax(mlp_classifier(z_prem, z_hypoprime))\n",
    "#     print(\"output3\")\n",
    "#     print(output3)\n",
    "#     loss3 = criterion(output3, target)\n",
    "#     print(loss3)\n",
    "\n",
    "#     loss4 = cross_entropy(output3, output2)\n",
    "#     print(\"loss4\")\n",
    "#     print(loss4)\n",
    "    \n",
    "    c_hypoprime = [{'params': c_hypo}]\n",
    "    optimizer = torch.optim.Adam(c_hypoprime)\n",
    "    for i in range(1000):\n",
    "        output2 = torch.nn.functional.softmax(classifier1.forward((premise_idx, hypothesis_idx))).detach()\n",
    "        z_hypoprime = inverter(c_hypoprime[0]['params'][0])\n",
    "        output3 = torch.nn.functional.softmax(mlp_classifier(z_prem, z_hypoprime))\n",
    "        loss4 = cross_entropy(output3, output2)\n",
    "        optimizer.zero_grad()\n",
    "        loss4.backward()\n",
    "        optimizer.step()\n",
    "#     print(c_hypoprime)\n",
    "    \n",
    "    nhypo_idx = autoencoder.generate(c_hypoprime[0]['params'][0], 10, False)\n",
    "    return nhypo_idx.squeeze(0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/game/.local/lib/python3.6/site-packages/ipykernel_launcher.py:58: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/game/.local/lib/python3.6/site-packages/ipykernel_launcher.py:60: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> a skateboarder doing a trick on a ramp <eos>\n",
      "<sos> a skateboarder performs an ollie of a ramp .\n",
      "<sos> people are doing an outdoor body of to watch <eos>\n",
      "Old  [0.2884084  0.38671458 0.324877  ]\n",
      "New  [0.6106356  0.26335478 0.12600963]\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> rider making high jump on motorcycle . <eos> <pad>\n",
      "<sos> man is competing in the x games . <pad>\n",
      "<sos> people are in mud with the street food <oov> <eos>\n",
      "Old  [0.25560644 0.38255015 0.3618434 ]\n",
      "New  [0.47206467 0.22966062 0.2982748 ]\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> man riding his bike pass a ship . <eos>\n",
      "<sos> there is a man riding a bike outside .\n",
      "<sos> the crowd is doing important to play their time inside\n",
      "Old  [0.52941716 0.16276962 0.30781326]\n",
      "New  [0.14251544 0.70748556 0.14999902]\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> people diving into a swimming pool . <eos> <pad>\n",
      "<sos> a woman drinks juice . <pad> <pad> <pad> <pad>\n",
      "<sos> men resting outside <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
      "Old  [0.4427708  0.20794557 0.34928358]\n",
      "New  [0.43485257 0.20298544 0.362162  ]\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> two men look up while hiking . <eos> <pad>\n",
      "<sos> two children look down while swimming . <pad> <pad>\n",
      "<sos> people are outdoors standing <eos> <eos> <eos> <eos> <eos> <eos>\n",
      "Old  [0.38732296 0.28267562 0.33000144]\n",
      "New  [0.58428764 0.15391482 0.26179752]\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> two bikers race uphill . <eos> <pad> <pad> <pad>\n",
      "<sos> two people are playing ball outside . <pad> <pad>\n",
      "<sos> people are standing outside and are together outside . <eos>\n",
      "Old  [0.52339536 0.22912027 0.24748437]\n",
      "New  [0.77371216 0.1009466  0.12534124]\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> a lady with brown hair standing . <eos> <pad>\n",
      "<sos> a lady is thinking about dinner . <pad> <pad>\n",
      "<sos> someone is wearing shirt <eos> <eos> <eos> <eos> building <eos>\n",
      "Old  [0.18163386 0.5661924  0.25217375]\n",
      "New  [0.48810393 0.260493   0.25140306]\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> professional rugby players on a field . <eos> <pad>\n",
      "<sos> a group is boarding a tour bus . <pad>\n",
      "<sos> there is a outside . <eos> <eos> <eos> a human\n",
      "Old  [0.30532274 0.34871688 0.34596035]\n",
      "New  [0.60720646 0.20887442 0.1839191 ]\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> a woman jogging through a field . <eos> <pad>\n",
      "<sos> a woman running outdoors . <pad> <pad> <pad> <pad>\n",
      "<sos> nobody is outside . <eos> <eos> a dress . <eos>\n",
      "Old  [0.46344268 0.21188255 0.3246748 ]\n",
      "New  [0.5103507  0.28161064 0.20803866]\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> two people in animal suits in a square .\n",
      "<sos> two people wearing animal dresses are talking . <pad>\n",
      "<sos> two old children listen to large their show off <eos>\n",
      "Old  [0.60441697 0.21213262 0.18345045]\n",
      "New  [0.07723571 0.7620964  0.1606679 ]\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> two people lounge in a large outdoor area .\n",
      "<sos> the people are outdoors . <pad> <pad> <pad> <pad>\n",
      "<sos> people outdoors are outside . <eos> a sidewalk . <eos>\n",
      "Old  [0.48620683 0.2976006  0.21619254]\n",
      "New  [0.590642   0.23310478 0.17625323]\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> a group of protesters are holding signs . <eos>\n",
      "<sos> protesters are holding signs against violence <pad> <pad> <pad>\n",
      "<sos> people are holding this individual . <eos> <eos> <eos> people\n",
      "Old  [0.6516602 0.2117803 0.1365595]\n",
      "New  [0.68127805 0.19228373 0.12643829]\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> a girl with blond-hair and a black shirt .\n",
      "<sos> a girl with blond-hair is wearing dark clothes .\n",
      "<sos> the small dog is bringing to be out . <eos>\n",
      "Old  [0.56311756 0.21095906 0.22592343]\n",
      "New  [0.2808755  0.4859156  0.23320895]\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> a person underneath a car with a jack .\n",
      "<sos> a person is inspecting a car <pad> <pad> <pad>\n",
      "<sos> a sits is wearing a <eos> <eos> <eos> <eos> <eos>\n",
      "Old  [0.47608104 0.1965324  0.3273865 ]\n",
      "New  [0.29192674 0.18318759 0.52488565]\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> a <oov> aquarium in a round brick building .\n",
      "<sos> a <oov> aquarium features many fish <oov> . <pad>\n",
      "<sos> people are wearing many people . <eos> a party <eos>\n",
      "Old  [0.28225705 0.4909412  0.22680181]\n",
      "New  [0.5407784  0.34692553 0.11229611]\n",
      "--------------------------------\n",
      "Target  tensor(1)\n",
      "<sos> three skydivers are in formation above the clouds .\n",
      "<sos> three men are skydiving towards the earth . <pad>\n",
      "<sos> two men are trying to ready for the free to\n",
      "Old  [0.24298243 0.45473945 0.30227807]\n",
      "New  [0.02167955 0.9361896  0.04213088]\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> the animals <oov> peacefully . <eos> <pad> <pad> <pad>\n",
      "<sos> there are more than one animal . <pad> <pad>\n",
      "<sos> people are being covered animals . <eos> <eos> <eos> protesters\n",
      "Old  [0.7091016  0.17119044 0.11970793]\n",
      "New  [0.6291189  0.22458214 0.14629893]\n",
      "--------------------------------\n",
      "Target  tensor(0)\n",
      "<sos> five african women talking . <eos> <pad> <pad> <pad>\n",
      "<sos> five african women are having a conversation <pad> <pad>\n",
      "<sos> groups of people asian hair . <eos> <eos> tall holding\n",
      "Old  [0.37701252 0.29074696 0.3322405 ]\n",
      "New  [0.58789057 0.20219322 0.20991628]\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> this family is walking their dog . <eos> <pad>\n",
      "<sos> this dog does not belong to the family <pad>\n",
      "<sos> an dog sleeping is sitting on grass on the couch\n",
      "Old  [0.11162943 0.64576066 0.24260989]\n",
      "New  [0.04392107 0.02548007 0.93059886]\n",
      "--------------------------------\n",
      "Target  tensor(2)\n",
      "<sos> three guys are playing in a field . <eos>\n",
      "<sos> dog sleeps on counter <pad> <pad> <pad> <pad> <pad>\n",
      "<sos> people standing <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
      "Old  [0.33193433 0.11163159 0.55643404]\n",
      "New  [0.43118408 0.20888564 0.35993025]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-268-c138610855b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mnh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperturb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Target '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-266-24c45deb0ae1>\u001b[0m in \u001b[0;36mperturb\u001b[0;34m(criterion, premise, hypothesis, target, premise_words, hypothesis_words, premise_length, hypothesis_length)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mloss4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mloss4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m#     print(c_hypoprime)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "niter = 0\n",
    "\n",
    "idx2words = dict(map(lambda x: (x[1], x[0]), corpus_vocab.items()))\n",
    "while niter < len(testloader):\n",
    "    niter += 1\n",
    "    batch = train_iter.next()\n",
    "    for p, h, t, pw, hw, pl, hl in zip(*batch):\n",
    "        nh = perturb(criterion, p.cuda(), h.cuda(), t.cuda(), pw, hw, pl, hl)\n",
    "        print('--------------------------------')\n",
    "        print('Target ', t)\n",
    "        print(' '.join(pw))\n",
    "        print(' '.join(hw))\n",
    "        nhw = (['<sos>'] + [idx2words[i] for i in nh])[:20]\n",
    "        print(' '.join(nhw))\n",
    "        print('Old ', classifier_pred(pw, hw))\n",
    "        print('New ', classifier_pred(pw, nhw))\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
